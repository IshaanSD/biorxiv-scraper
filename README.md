<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

# bioRxiv Scraper

> A simple web scraper for scraping articles and their metadata from bioRxiv.


## Install

```
git clone https://github.com/JohnGiorgi/biorxiv_scraper.git
cd biorxiv-scraper
pip install -e .
```

## How to use

Everything happens via the `bioRxivScraper` class. Begin by creating an instance
<div class="codecell" markdown="1">
<div class="input_area" markdown="1">

```python
from biorxiv_scraper.core import bioRxivScraper

scraper = bioRxivScraper()
```

</div>

</div>

You can then call its various methods for scraping bioRxiv. For example, to scrape all articles uploaded in 2018 under the subject area "Animal Behavior and Cognition"
<div class="codecell" markdown="1">
<div class="input_area" markdown="1">

```python
scraped_content = scraper.by_subject_area("Animal Behavior and Cognition", 2019)
```

</div>

</div>

`scraped_content` is a dictionary keyed by [doi](https://www.doi.org/), that contains the scraped data and metadata for each article
